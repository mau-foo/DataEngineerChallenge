{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5e43ff-9cbe-4edf-8af3-06885036e375",
   "metadata": {},
   "source": [
    "# PayPay Corporation Data Engineering Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6acba7-c284-499e-97de-43672cda0cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://YuYu-Spectre-COM:4040\n",
       "SparkContext available as 'sc' (version = 3.1.2, master = local[*], app id = local-1625621447814)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.DataTypes\r\n",
       "import org.apache.spark.sql.expressions.Window\r\n",
       "import org.apache.spark.sql.functions.lag\r\n",
       "import org.apache.spark.sql.functions.unix_timestamp\r\n",
       "import org.apache.spark.sql.functions.when\r\n",
       "import org.apache.spark.sql.functions.sum\r\n",
       "import org.apache.spark.sql.functions.countDistinct\r\n",
       "TIME_ZONE: String = UTC\r\n",
       "TIME_INTERVAL_THRESHOLD_IN_SECONDS: Int = 900\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.DataTypes\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions.lag\n",
    "import org.apache.spark.sql.functions.unix_timestamp\n",
    "import org.apache.spark.sql.functions.when\n",
    "import org.apache.spark.sql.functions.sum\n",
    "import org.apache.spark.sql.functions.countDistinct\n",
    "\n",
    "// UTC timezone\n",
    "val TIME_ZONE = \"UTC\"   \n",
    "\n",
    "// Session interval of 15 minutes\n",
    "val TIME_INTERVAL_THRESHOLD_IN_SECONDS = 15 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846330dd-f308-4664-b419-a81852dccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Setting UTC timezone for spark session which is necessary to calculate the difference between timestamp datatypes\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", TIME_ZONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b5505-5df4-4393-9507-b6957cb53ebb",
   "metadata": {},
   "source": [
    "## Example of the data from the Amazon marketplace web log file\n",
    "\n",
    "![title](data_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af571764-be35-4ace-8e0d-fe076074b446",
   "metadata": {},
   "source": [
    "Screenshot for the example of the data and any other information such as the schema of the data can be found in the following [link](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/access-log-collection.html#access-log-entry-format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56b6fd8-cb4c-481f-9398-bef43130bef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wholeDF: org.apache.spark.sql.DataFrame = [value: string]\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read in file in dataframe\n",
    "var wholeDF = spark.read.text(\"data/2015_07_22_mktplace_shop_web_log_sample.log.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53609a-64d6-4a2b-bae4-8bf709faec14",
   "metadata": {},
   "source": [
    "# Prepping data before conducting analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad0b772-f12c-4cab-b003-b5db728107f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitDF: org.apache.spark.sql.DataFrame = [time: timestamp, name_of_balancer: string ... 13 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* Creating new dataframe to separate out columns from the original dataframe which had all data stored under one column\n",
    "   Used regex pattern within the split because we are spliting on whitespace and request has multiple words within its column we want to ignore those whitespaces within double quotes\n",
    "   Regex pattern was found at the following link https://stackabuse.com/regex-splitting-by-character-unless-in-quotes\n",
    "*/\n",
    "var splitDF = wholeDF.withColumn(\"_columns\", split($\"value\", \" (?=([^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\")).select(     \n",
    "    $\"_columns\".getItem(0).cast(DataTypes.TimestampType).as(\"time\"),\n",
    "    $\"_columns\".getItem(1).as(\"name_of_balancer\"),\n",
    "    $\"_columns\".getItem(2).as(\"ip_address\"),\n",
    "    $\"_columns\".getItem(3).as(\"private_address\"),\n",
    "    $\"_columns\".getItem(4).as(\"request_processing_time\"),\n",
    "    $\"_columns\".getItem(5).as(\"backend_processing_time\"),\n",
    "    $\"_columns\".getItem(6).as(\"response_processing_time\"),\n",
    "    $\"_columns\".getItem(7).as(\"elb_status_code\"),\n",
    "    $\"_columns\".getItem(8).as(\"backend_status_code\"),\n",
    "    $\"_columns\".getItem(9).as(\"received_bytes\"),\n",
    "    $\"_columns\".getItem(10).as(\"sent_bytes\"),\n",
    "    $\"_columns\".getItem(11).as(\"request\"),\n",
    "    $\"_columns\".getItem(12).as(\"user_agent\"),\n",
    "    $\"_columns\".getItem(13).as(\"ssl_cipher\"),\n",
    "    $\"_columns\".getItem(14).as(\"ssl_protocol\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86666332-8997-459b-9be0-ea28ea50d134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+---------------+-----------------------+-----------------------+------------------------+---------------+-------------------+--------------+----------+--------------------+--------------------+--------------------+------------+\n",
      "|                time|name_of_balancer|          ip_address|private_address|request_processing_time|backend_processing_time|response_processing_time|elb_status_code|backend_status_code|received_bytes|sent_bytes|             request|          user_agent|          ssl_cipher|ssl_protocol|\n",
      "+--------------------+----------------+--------------------+---------------+-----------------------+-----------------------+------------------------+---------------+-------------------+--------------+----------+--------------------+--------------------+--------------------+------------+\n",
      "|2015-07-22 09:00:...|marketpalce-shop|123.242.248.130:5...|  10.0.6.158:80|               0.000022|               0.026109|                 0.00002|            200|                200|             0|       699|\"GET https://payt...|\"Mozilla/5.0 (Win...|ECDHE-RSA-AES128-...|     TLSv1.2|\n",
      "|2015-07-22 09:00:...|marketpalce-shop| 203.91.211.44:51402|  10.0.4.150:80|               0.000024|                0.15334|                0.000026|            200|                200|             0|      1497|\"GET https://payt...|\"Mozilla/5.0 (Win...|ECDHE-RSA-AES128-...|     TLSv1.2|\n",
      "|2015-07-22 09:00:...|marketpalce-shop|   1.39.32.179:56419|  10.0.4.244:80|               0.000024|               0.164958|                0.000017|            200|                200|             0|       157|\"GET https://payt...|\"Mozilla/5.0 (Win...|ECDHE-RSA-AES128-...|     TLSv1.2|\n",
      "|2015-07-22 09:00:...|marketpalce-shop|180.179.213.94:48725|  10.0.6.108:80|                0.00002|               0.002333|                0.000021|            200|                200|             0|     35734|\"GET https://payt...|                 \"-\"|ECDHE-RSA-AES128-...|     TLSv1.2|\n",
      "|2015-07-22 09:00:...|marketpalce-shop|120.59.192.208:13527|  10.0.4.217:80|               0.000024|               0.015091|                0.000016|            200|                200|            68|       640|\"POST https://pay...|\"Mozilla/5.0 (Win...|ECDHE-RSA-AES128-...|     TLSv1.2|\n",
      "+--------------------+----------------+--------------------+---------------+-----------------------+-----------------------+------------------------+---------------+-------------------+--------------+----------+--------------------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// First five rows of dataframe\n",
    "splitDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1fd59e-4a51-4ac1-82fa-d79ab7016683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitDF: org.apache.spark.sql.DataFrame = [time: timestamp, name_of_balancer: string ... 14 more fields]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add column - previous timestamp for each record\n",
    "splitDF = splitDF.withColumn(\"previous_time\", \n",
    "                             lag($\"time\", 1, null).over(Window.partitionBy(\"ip_address\").orderBy(\"time\"))\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfac3f3-ebb6-48e9-a061-56561be69949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitDF: org.apache.spark.sql.DataFrame = [time: timestamp, name_of_balancer: string ... 15 more fields]\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add column - time difference in seconds between current timestamp and previous timestamp\n",
    "splitDF = splitDF.withColumn(\"time_difference\", \n",
    "                             col(\"time\").cast(\"long\") - col(\"previous_time\").cast(\"long\")\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd0767d-2dd9-4d60-acd4-20e5e0f41daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitDF: org.apache.spark.sql.DataFrame = [time: timestamp, name_of_balancer: string ... 16 more fields]\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add column - whether the record is new session or not determined by whether time difference it is greater than the 15 minute interval or if time difference is null  \n",
    "splitDF = splitDF.withColumn(\"is_new_session\",\n",
    "                             when(col(\"time_difference\").$greater(TIME_INTERVAL_THRESHOLD_IN_SECONDS)\n",
    "                                  .or(col(\"time_difference\").isNull), 1).otherwise(0)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae79dda1-f78e-489f-88b6-a92bcfa2a817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitDF: org.apache.spark.sql.DataFrame = [time: timestamp, name_of_balancer: string ... 17 more fields]\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add column - used to flag each new session per IP address \n",
    "splitDF = splitDF.withColumn(\"session_seq\",\n",
    "                             sum(col(\"is_new_session\")).over(Window.partitionBy(col(\"ip_address\")).orderBy(\"time\"))\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2449e29-64c8-48bd-bf28-ea458b4109e1",
   "metadata": {},
   "source": [
    "# PayPay Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355afcdf-3d0e-4782-bd3d-f05a1cd12bd7",
   "metadata": {},
   "source": [
    "## Challenge 1: Sessionize the web log by IP. Sessionize = aggregrate all page hits by visitor/IP during a session\n",
    "\n",
    "Explanation: from my understanding of the first challenge, we want to get count of all page hits which I interrupted a hit as request back to the load balancer (a record) so in this situation we do count and group by ip address to get count of records (hits) by ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b71b7f-5e09-4963-8f83-ef90f827b670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countByIP: org.apache.spark.sql.DataFrame = [ip_address: string, count: bigint]\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var countByIP = splitDF.groupBy(\"ip_address\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de08a25-6fa8-4fca-ba0d-ca78272270cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|ip_address           |count|\n",
      "+---------------------+-----+\n",
      "|107.167.107.202:37235|3    |\n",
      "|14.139.253.18:52731  |1    |\n",
      "|116.202.36.65:41369  |1    |\n",
      "|1.38.22.148:24378    |2    |\n",
      "|219.64.127.129:24106 |3    |\n",
      "+---------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// First five rows of dataframe\n",
    "countByIP.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8e916-26a0-42dc-be24-c8c433fa6bac",
   "metadata": {},
   "source": [
    "## Challenge 2: Determine the average session time\n",
    "\n",
    "Explanation: sum the duration of each page hit then divide by the number of sessions (average session duration is in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42b7914-7969-4e33-bdb1-4ac662b1ab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgSessionTime: org.apache.spark.sql.DataFrame = [average_session_time: double]\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var avgSessionTime = splitDF.select(sum(\"time_difference\") / sum(\"is_new_session\")).withColumnRenamed(\"(sum(time_difference) / sum(is_new_session))\", \"average_session_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51304c70-f0ac-4201-84cb-e8b8efa0a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|average_session_time|\n",
      "+--------------------+\n",
      "|   1552.721265586177|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Time is in seconds (conversion in minutes: 25)\n",
    "avgSessionTime.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e117892-adc2-4dd2-b70e-597ceeca7b31",
   "metadata": {},
   "source": [
    "## Challenge 3: Determine unique URL visits per session. To clarify, count a hit to a unique URL only once per session\n",
    "\n",
    "Explanation: sum the duration of each page hit then divide by the number of sessions (average session duration is in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069e54d8-c34b-43df-ab8b-5d244747556a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countUniqueURL: org.apache.spark.sql.DataFrame = [ip_address: string, session_seq: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculate counts of distinct URLs by ip address and session sequence\n",
    "var countUniqueURL = splitDF.groupBy(\"ip_address\", \"session_seq\").agg(countDistinct(\"request\").alias(\"unique_url_count\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0c795c-46e0-44c1-b150-1d598806b6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+----------------+\n",
      "|ip_address         |session_seq|unique_url_count|\n",
      "+-------------------+-----------+----------------+\n",
      "|1.187.167.214:65257|1          |1               |\n",
      "|1.187.170.77:64760 |1          |1               |\n",
      "|1.187.179.217:34549|1          |3               |\n",
      "|1.187.185.201:46980|1          |1               |\n",
      "|1.187.202.35:38668 |1          |4               |\n",
      "+-------------------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// First five rows of dataframe\n",
    "countUniqueURL.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604b62a-26c7-4b72-9b11-b97a86092d14",
   "metadata": {},
   "source": [
    "## Challenge 4: Find the most engaged users, ie the IPs with the longest session times\n",
    "Explanation: summarize time spent within each session (session seq) than order by total session time in descending order to display 10 top longest sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa02abf-df7a-4ef2-8109-ad18368f6ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mostEngagedUsers: org.apache.spark.sql.DataFrame = [ip_address: string, session_seq: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Aggregating to determine the longest session time by session and ip address in seconds\n",
    "var mostEngagedUsers = splitDF.groupBy(\"ip_address\", \"session_seq\").sum(\"time_difference\").withColumnRenamed(\"sum(time_difference)\", \"total_session_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cc3ba06-3a96-428d-bef5-cc9e920e1a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------------+\n",
      "|         ip_address|session_seq|total_session_time|\n",
      "+-------------------+-----------+------------------+\n",
      "|106.186.23.95:35629|          2|             66511|\n",
      "|106.186.23.95:35632|          2|             66511|\n",
      "|106.186.23.95:35626|          2|             66511|\n",
      "|106.186.23.95:39247|          2|             66500|\n",
      "|106.186.23.95:39646|          2|             66500|\n",
      "|106.186.23.95:40448|          2|             66500|\n",
      "|106.186.23.95:40598|          2|             66500|\n",
      "|106.186.23.95:39944|          2|             66500|\n",
      "|106.186.23.95:40184|          2|             66500|\n",
      "|106.186.23.95:39994|          2|             66499|\n",
      "+-------------------+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Display the TOP 10 longest sessions\n",
    "mostEngagedUsers.sort(desc(\"sum(time_difference)\")).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
